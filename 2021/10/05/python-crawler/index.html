<!DOCTYPE html><html lang="zh-TW"><head><meta charset="utf-8"><meta name="theme-color" content="#0077B5"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="google-site-verification" content="tfWfY4bkeILtxNyUg9UGfVkCNvKtAauF2r9WDQs8kBM"><meta property="fb:pages" content="219138595338413"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="嗨，我是林彥成，是個喜歡爬山的前端工程師，專注在 React.js 的相關開發，這個部落格會分享網站技術、職涯發展、個人成長和產業觀察相關文章。"><meta name="keyword" content="前端三分鐘, 前端, React.js, 林彥成, 網站技術, 職涯發展, 個人成長, 產業觀察"><meta property="og:image" content="/img/icon_wechat.png"><link rel="shortcut icon" href="/img/favicon.ico"><title>Python Crawler 爬蟲入門範例: 用一百行不到的程式，把網站通通爬下來 | 前端三分鐘 | 一起用三分鐘分享技術與知識</title><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin><link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin="anonymous"><link rel="canonical" href="https://linyencheng.github.io/2021/10/05/python-crawler/"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/blog.min.css"><link rel="stylesheet" href="/css/highlight.css"><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/feed.xml" title="前端三分鐘" type="application/atom+xml"></head><body ontouchstart=""><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class="container-fluid"><div class="navbar-header page-scroll"><button type="button" class="navbar-toggle"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button> <a class="navbar-brand" href="/">前端三分鐘</a></div><div id="huxblog_navbar"><div class="navbar-collapse"><ul class="nav navbar-nav navbar-right"><li><a title="首頁" href="/">首頁</a></li><li><a href="/categories/">分類</a></li><li><a href="/about/">關於</a></li><li><a href="/archives/">列表</a></li><li><a href="/tags/">標籤</a></li><li><a title="隱私權政策" href="/pravicy">隱私權政策</a></li></ul></div></div></div></nav><script async>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");function handleMagic(e){0<$navbar.className.indexOf("in")?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}$toggle.addEventListener("click",handleMagic)</script><style>.intro-header{position:relative;overflow:hidden;background:repeating-linear-gradient(0deg,rgba(255,255,255,.3) 0,rgba(255,255,255,.3) 1px,transparent 1px,transparent 10px),repeating-linear-gradient(90deg,rgba(255,255,255,.3) 0,rgba(255,255,255,.3) 1px,transparent 1px,transparent 10px);background-color:#b4dbf8}@media (max-width:768px){.mobile-hidden{display:none}}</style><progress value="0" id="progressBar" class="flat"><div class="progress-container"><span class="progress-bar"></span></div></progress><header class="intro-header"><div class="geometric-pattern"><div class="shape"></div><div class="shape"></div><div class="shape"></div><div class="shape mobile-hidden"></div><div class="shape mobile-hidden"></div><div class="shape mobile-hidden"></div></div><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="post-heading"><div class="tags"><a class="tag" href="/tags/#網站技術" title="網站技術">網站技術</a> <a class="tag" href="/tags/#Backend" title="Backend">Backend</a> <a class="tag" href="/tags/#Python" title="Python">Python</a></div><h1 class="mb-0"><span>Python Crawler 爬蟲入門範例</span> <span class="subheading mb-2">用一百行不到的程式，把網站通通爬下來</span></h1><a class="post-user-meta post-user-meta--big" href="/about"><img loading="lazy" alt="me" class="userPhoto d-inline-block" src="/img/me_icon.jpg"><div class="d-inline-block"><span class="user-name" style="color:#fff">林彥成</span><br><span style="color:#fff">2021-10-05 | 4 min.</span> <span id="viewCountTotal" style="color:#fff"></span></div></a></div></div></div></div></header><article id="article-post"><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-1 col-md-10 col-md-offset-1 post-container"><div id="toc" class="toc-article"><strong class="toc-title h3">文章目錄</strong><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E9%BA%BC%E6%98%AF%E7%B6%B2%E7%AB%99%E7%88%AC%E8%9F%B2"><span class="toc-number">1.</span> <span class="toc-text">什麼是網站爬蟲</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Python-%E7%B6%B2%E7%AB%99%E7%88%AC%E8%9F%B2%E5%B7%A5%E5%85%B7"><span class="toc-number">2.</span> <span class="toc-text">Python 網站爬蟲工具</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B6%B2%E7%AB%99%E5%8F%8D%E7%88%AC%E8%9F%B2"><span class="toc-number">3.</span> <span class="toc-text">網站反爬蟲</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Python-Selenium-%E7%88%AC%E8%9F%B2%E5%AF%A6%E4%BD%9C"><span class="toc-number">4.</span> <span class="toc-text">Python Selenium 爬蟲實作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Python-Requests-%E7%88%AC%E8%9F%B2%E5%AF%A6%E4%BD%9C"><span class="toc-number">5.</span> <span class="toc-text">Python Requests 爬蟲實作</span></a></li></ol></div><br><div class="google-ad"><ins class="adsbygoogle" style="display:block" data-ad-format="fluid" data-ad-layout-key="-h4+1+1q-1t-2x" data-ad-client="ca-pub-1297466993744883" data-ad-slot="9012117796"></ins></div><h2 id="什麼是網站爬蟲"><a href="#什麼是網站爬蟲" class="headerlink" title="什麼是網站爬蟲"></a>什麼是網站爬蟲</h2><p>網站爬蟲可以將爬取的頁面儲存，透過網站爬蟲，開發者可以蒐集網路更多的資源供後續使用。</p><p>舉一個大家都聽過的應用，Google 搜尋引擎背後其實也是透過爬蟲的技術來將網站資料存下來進行索引來提供用戶搜尋。</p><p>由於爬蟲存取網站的過程還是會消耗站台系統資源，所以身為爬蟲開發者要遵守的價值觀有兩點如下:</p><ul><li><strong>不要打爆對方</strong></li><li>遵守 robots.txt 中定義規則，這些規則會標註禁止或開放存取哪些路徑</li></ul><h2 id="Python-網站爬蟲工具"><a href="#Python-網站爬蟲工具" class="headerlink" title="Python 網站爬蟲工具"></a>Python 網站爬蟲工具</h2><p>Python 的爬蟲工具常見有以下兩種:</p><ul><li>selenium: 萬用門檻低</li><li>requests: 效率好、較不易受 JavaScript 影響，因為不會抓照片、UI 變化等等，只會抓整個 html 的文本</li></ul><p>常見的網站爬蟲情境如下:</p><ul><li>一步可爬: 資料就放在頁面中的表格</li><li>查詢後爬: 需要透過搜尋篩選框</li><li>先登入後查詢才能爬<ul><li>先用 selenium 登入再用 requests 打包資料</li><li>驗證碼破解<ul><li>Tesseract</li><li>Tesseract + keras</li></ul></li></ul></li></ul><h2 id="網站反爬蟲"><a href="#網站反爬蟲" class="headerlink" title="網站反爬蟲"></a>網站反爬蟲</h2><p>網站要反爬蟲就要製造障礙，去想說爬蟲怎麼爬會難爬取資料，一般的反爬蟲如下:</p><ul><li>登入後才能查詢，擋 header 或是 cookie</li><li>CSRFPreventionSalt 改成一次性</li><li>驗證碼 (選圖片、加減乘除)</li><li>隨機跳 pop window 或是 alert</li><li>Table 變成照片或 PDF 會更難爬</li><li>xPath 爬蟲，xPath 中新增 DIV，不影響使用者體驗下還能反爬蟲</li></ul><p>流量要先壓力測試，不然被爬幾下就壞了也很糟糕:</p><ul><li>從 GA、Log 去看流量，然後直接擋掉</li><li>locust 套件</li></ul><h2 id="Python-Selenium-爬蟲實作"><a href="#Python-Selenium-爬蟲實作" class="headerlink" title="Python Selenium 爬蟲實作"></a>Python Selenium 爬蟲實作</h2><p>由於小編的電腦是從大學用到現在已經有點年老，所以這次直接使用 Google 的 Colab 免費使用 GPU 的運算資源，Colab 的使用方法跟 Jupyter notebook 一樣，可以直接執行 Python 的程式碼。</p><p>來示範一步可爬的網站，以玉山銀行的網站為例:</p><ol start="0"><li>Colab 需要先安裝才能夠使用 selenium</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">!pip install selenium</span><br><span class="line">!apt-get update <span class="comment"># to update ubuntu to correctly run apt install</span></span><br><span class="line">!apt install chromium-chromedriver</span><br><span class="line">!cp /usr/lib/chromium-browser/chromedriver /usr/<span class="built_in">bin</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.insert(<span class="number">0</span>,<span class="string">&#x27;/usr/lib/chromium-browser/chromedriver&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li>引入資料處理常見的 pandas、還有本次爬蟲主角 selenium</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br></pre></td></tr></table></figure><ol start="2"><li>透過 webdriver 指定瀏覽器為 chrome，並且設定相關參數，最後透過瀏覽器開啟網站</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">chrome_options = webdriver.ChromeOptions()</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--no-sandbox&#x27;</span>)</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;--disable-dev-shm-usage&#x27;</span>)</span><br><span class="line">browser = webdriver.Chrome(<span class="string">&#x27;chromedriver&#x27;</span>,chrome_options=chrome_options)</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.esunbank.com.tw/bank/about/announcement/announcement?i=eqQb451_o06vZeJpBZLLLQ&amp;amp;p=QEdQ8PAaO0GrIzIcAevp0A&amp;amp;d=hxK-VOJqWkGADb4tgPQH4Q&#x27;</span></span><br><span class="line">browser.get(url)</span><br></pre></td></tr></table></figure><ol start="3"><li>透過 Pandas 套件提供的 <code>read_html()</code> 輕鬆讀取網頁中的 <code>&lt;table&gt;</code> 表格，這裡就直接選取第一個</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.read_html(browser.page_source)[<span class="number">0</span>].head()</span><br></pre></td></tr></table></figure><ol start="4"><li>或著我們也可以透過 xpath 來進行指定 html 的範圍，然後也是一樣餵給 <code>read_html()</code></li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">element_xpath = <span class="string">&#x27;//*[@id=&quot;mainform&quot;]/div[10]/div[2]/div[2]/table[1]&#x27;</span></span><br><span class="line">target_table = browser.find_element_by_xpath(element_xpath)</span><br><span class="line">html_string = target_table.get_attribute(<span class="string">&#x27;outerHTML&#x27;</span>)</span><br><span class="line">pd.read_html(html_string)[<span class="number">0</span>].head()</span><br></pre></td></tr></table></figure><ol start="5"><li>如果遇到彈跳視窗來阻擋，一樣可以透過 xpath 先找到，然後透過 JavaScript 把 Element 從 Dom 中移除。</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 移除彈跳視窗</span></span><br><span class="line">element = browser.find_element_by_xpath(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">browser.execute_script(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">var element = arguments[0];</span></span><br><span class="line"><span class="string">element.parentNode.removeChild(element);</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>, element);</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Python-Requests-爬蟲實作"><a href="#Python-Requests-爬蟲實作" class="headerlink" title="Python Requests 爬蟲實作"></a>Python Requests 爬蟲實作</h2><p>requests 不同於 selenium，抓取下來的會是純文本，不包含相關圖片等靜態資源，所以對伺服器的負擔相對較小，接下來要示範先查詢後爬的網站，這邊會以 104 人力銀行網站為例，需要透過搜尋篩選框來篩選職缺訊息。</p><p>這個 API 明顯有幾個參數，所以接下來就會需要去整理相關資訊</p><ul><li>indcat: 產業別</li><li>area: 地區</li><li>page: 頁數</li></ul><ol><li>引入資料處理常見的 pandas、還有本次爬蟲主角 requests</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><ol start="2"><li>網站有基本反爬蟲所以需要設定 Headers 來騙過伺服器，最後透過 requests 開始抓取資料</li></ol><ul><li>User-Agent (用戶端)資訊: ‘Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;84.0.4147.135 Safari&#x2F;537.36’</li><li>Referer (從哪裏來): ‘<a target="_blank" rel="noopener" href="https://www.104.com.tw/">https://www.104.com.tw/</a>‘</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;Referer&#x27;</span>: <span class="string">&#x27;https://www.104.com.tw/&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">url= <span class="string">&#x27;https://www.104.com.tw/jobs/search/list?ro=1&amp;indcat=1003000000&amp;area=6001001000&amp;order=11&amp;asc=0&amp;page=&amp;mode=l&#x27;</span></span><br><span class="line">resp = requests.get(url, headers=headers)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="3"><li>透過 Pandas 套件提供的 <code>DataFrame</code> 將資料存下來，先顯示個三筆看看</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(resp.json()[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;list&#x27;</span>]).head(<span class="number">3</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="4"><li>當然一次爬個 10 頁也是沒問題</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">df = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>):</span><br><span class="line">    url= <span class="string">f&#x27;https://www.104.com.tw/jobs/search/list?ro=1&amp;indcat=1003000000&amp;area=6001001000&amp;order=11&amp;asc=0&amp;page=<span class="subst">&#123;page&#125;</span>&amp;mode=l&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(url)</span><br><span class="line">    resp = requests.get(url, headers=headers)</span><br><span class="line">    ndf = pd.DataFrame(resp.json()[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;list&#x27;</span>])</span><br><span class="line">    df.append(ndf)</span><br><span class="line">    <span class="keyword">if</span> ndf.shape[<span class="number">0</span>] &lt; <span class="number">30</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">df = pd.concat(df, ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><ol start="5"><li>接著是整理地區跟產業別的篩選條件，舉地區資料如下，會透過 explode 把 array 中的 n 做展開，然後透過 apply 去整理資料，最後透過 loc 把剛剛展開的 n 拿掉生成新的 Dataframe</li></ol><ul><li>explode 的說明可以參考<a target="_blank" rel="noopener" href="https://www.w3resource.com/pandas/dataframe/dataframe-explode.php">連結</a></li><li>apply 的說明可以參考<a target="_blank" rel="noopener" href="https://www.w3resource.com/pandas/dataframe/dataframe-apply.php">連結</a></li><li>loc 的說明可以參考<a target="_blank" rel="noopener" href="https://www.w3resource.com/pandas/dataframe/dataframe-loc.php">連結</a></li></ul><p>第 0 筆的 n 資料如下:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;des&quot;</span><span class="punctuation">:</span> <span class="string">&quot;台北市&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;no&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6001001000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;n&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;des&quot;</span><span class="punctuation">:</span> <span class="string">&quot;台北市中正區&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;no&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6001001001&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;des&quot;</span><span class="punctuation">:</span> <span class="string">&quot;台北市大同區&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;no&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6001001002&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;des&quot;</span><span class="punctuation">:</span> <span class="string">&quot;新北市&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;no&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6001002000&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;n&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;des&quot;</span><span class="punctuation">:</span> <span class="string">&quot;新北市萬里區&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;no&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6001002001&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;des&quot;</span><span class="punctuation">:</span> <span class="string">&quot;新北市金山區&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;no&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6001002002&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 地區</span></span><br><span class="line">url = <span class="string">&#x27;https://static.104.com.tw/category-tool/json/Area.json&#x27;</span></span><br><span class="line"><span class="comment"># 抓出第 0 筆的 n</span></span><br><span class="line">areacode = pd.DataFrame(requests.get(url).json()[<span class="number">0</span>][<span class="string">&#x27;n&#x27;</span>])</span><br><span class="line"><span class="comment"># 把 n 展開</span></span><br><span class="line">areacode = areacode.explode(<span class="string">&#x27;n&#x27;</span>)</span><br><span class="line"><span class="comment"># 取出展開的 n 中的 des 當成欄位中的 des2</span></span><br><span class="line">areacode[<span class="string">&#x27;des2&#x27;</span>] = areacode[<span class="string">&#x27;n&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="string">&#x27;des&#x27;</span>])</span><br><span class="line"><span class="comment"># 取出展開的 n 中的 no 當成欄位中的 no2</span></span><br><span class="line">areacode[<span class="string">&#x27;no2&#x27;</span>] = areacode[<span class="string">&#x27;n&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="string">&#x27;no&#x27;</span>])</span><br><span class="line"><span class="comment"># 拿掉展開的 n 欄位</span></span><br><span class="line">areacode = areacode.loc[:,[<span class="string">&#x27;des&#x27;</span>, <span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;des2&#x27;</span>, <span class="string">&#x27;no2&#x27;</span>]]</span><br><span class="line">areacode</span><br><span class="line"></span><br><span class="line"><span class="comment"># 產業別</span></span><br><span class="line">url = <span class="string">&#x27;https://static.104.com.tw/category-tool/json/Indust.json&#x27;</span></span><br><span class="line">Indust = pd.DataFrame(requests.get(url).json())</span><br><span class="line">Indust = Indust.explode(<span class="string">&#x27;n&#x27;</span>)</span><br><span class="line">Indust[<span class="string">&#x27;des2&#x27;</span>] = Indust[<span class="string">&#x27;n&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="string">&#x27;des&#x27;</span>])</span><br><span class="line">Indust[<span class="string">&#x27;no2&#x27;</span>] = Indust[<span class="string">&#x27;n&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="string">&#x27;no&#x27;</span>])</span><br><span class="line">Indust[<span class="string">&#x27;n2&#x27;</span>] = Indust[<span class="string">&#x27;n&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="string">&#x27;n&#x27;</span>])</span><br><span class="line">Indust = Indust.explode(<span class="string">&#x27;n2&#x27;</span>)</span><br><span class="line">Indust[<span class="string">&#x27;des3&#x27;</span>] = Indust[<span class="string">&#x27;n2&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="string">&#x27;des&#x27;</span>])</span><br><span class="line">Indust[<span class="string">&#x27;no3&#x27;</span>] = Indust[<span class="string">&#x27;n2&#x27;</span>].apply(<span class="keyword">lambda</span> x: x[<span class="string">&#x27;no&#x27;</span>])</span><br><span class="line">Indust = Indust.loc[:,[<span class="string">&#x27;des&#x27;</span>, <span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;des2&#x27;</span>, <span class="string">&#x27;no2&#x27;</span>, <span class="string">&#x27;des3&#x27;</span>, <span class="string">&#x27;no3&#x27;</span>]]</span><br><span class="line">Indust</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="6"><li>跑迴圈把所有的資料抓下來</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">df = []</span><br><span class="line"><span class="keyword">for</span> area <span class="keyword">in</span> areacode[<span class="string">&#x27;no2&#x27;</span>].unique():</span><br><span class="line">    <span class="keyword">for</span> indcat <span class="keyword">in</span> Indust[<span class="string">&#x27;no2&#x27;</span>].unique():</span><br><span class="line">        page = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> page &lt;= <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                url = <span class="string">f&#x27;https://www.104.com.tw/jobs/search/list?ro=1&amp;indcat=<span class="subst">&#123;indcat&#125;</span>&amp;area=<span class="subst">&#123;area&#125;</span>&amp;order=11&amp;asc=0&amp;page=<span class="subst">&#123;page&#125;</span>&amp;mode=l&#x27;</span></span><br><span class="line">                <span class="built_in">print</span>(url)</span><br><span class="line">                resp = requests.get(url, headers=headers)</span><br><span class="line">                ndf = pd.DataFrame(resp.json()[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;list&#x27;</span>])</span><br><span class="line">                df.append(ndf)</span><br><span class="line">                <span class="keyword">if</span> ndf.shape[<span class="number">0</span>] &lt; <span class="number">30</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                page = page + <span class="number">1</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;==================== Error and retry ====================&#x27;</span>)</span><br><span class="line">        clear_output()</span><br><span class="line">df = pd.concat(df, ignore_index=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><ol start="7"><li>把檔案存起來，收工</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df.to_excel(<span class="string">&#x27;./data/job_abs.xlsx&#x27;</span>)</span><br><span class="line">df.to_csv(<span class="string">&#x27;./data/job_abs.csv&#x27;</span>)</span><br><span class="line">df.to_pickle(<span class="string">&#x27;./data/job_abs.pkl&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>為了避免爬太久，有把條件減少，Github 中完整的 Gist 如下:</p><script src="https://gist.github.com/LinYenCheng/c480e235d83dcfa54b30e07a3a0a92c3.js"></script><div class="google-ad"><ins class="adsbygoogle" style="display:block" data-ad-format="fluid" data-ad-layout-key="-h4+1+1q-1t-2x" data-ad-client="ca-pub-1297466993744883" data-ad-slot="9012117796"></ins></div><hr><div class="more-article hidden-md hidden-lg"><span class="h4">更多相關文章</span><hr class="hidden-sm hidden-xs"><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-img"><img alt="yencheng" loading="lazy" src="https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png"></div><div class="popular-posts-title"><h3><a href="/2021/10/08/python-fast-api/" title="Python FastAPI 快速入門" rel="bookmark">Python FastAPI 快速入門</a></h3><span>2021-10-08<span></span></span></div></li><li class="popular-posts-item"><div class="popular-posts-img"><img alt="yencheng" loading="lazy" src="/2019/08/01/python-hypothesis-testing/hypothesis-testing.png"></div><div class="popular-posts-title"><h3><a href="/2019/08/01/python-hypothesis-testing/" title="Python Hypothesis Testing (假設檢定)" rel="bookmark">Python Hypothesis Testing (假設檢定)</a></h3><span>2019-08-01<span></span></span></div></li><li class="popular-posts-item"><div class="popular-posts-img"><img alt="yencheng" loading="lazy" src="https://i0.wp.com/readlearncode.com/wp-content/uploads/2017/02/java-ee-7-apis.png?ssl=1"></div><div class="popular-posts-title"><h3><a href="/2018/04/05/java-web/" title="Java Web API (RESTful API) 教學" rel="bookmark">Java Web API (RESTful API) 教學</a></h3><span>2018-04-05<span></span></span></div></li><li class="popular-posts-item"><div class="popular-posts-img"><img alt="yencheng" loading="lazy" src="https://linyencheng.github.io/img/icon_48.png"></div><div class="popular-posts-title"><h3><a href="/2019/09/07/tool-mongoose-mongo/" title="Mongoose 是什麼" rel="bookmark">Mongoose 是什麼</a></h3><span>2019-09-07<span></span></span></div></li><li class="popular-posts-item"><div class="popular-posts-img"><img alt="yencheng" loading="lazy" src="https://slack.engineering/wp-content/uploads/sites/7/2021/08/image3.png?resize=640,550"></div><div class="popular-posts-title"><h3><a href="/2022/09/16/relationships-between-frontend-and-backend/backend-api-design/" title="API 系統設計方法 X 面試指南" rel="bookmark">API 系統設計方法 X 面試指南</a></h3><span>2022-09-16<span></span></span></div></li></ul></div><hr class="hidden-md hidden-lg"><span id="likeCo" class="pl-4 ml-4" style="color:#9b9b9b">喜歡這篇文章，請幫忙拍拍手喔 🤣</span><hr><div class="likecoin-embed likecoin-button" style="margin:0;max-height:185px;min-height:185px" data-liker-id="linyencheng-tw" data-href="https://linyencheng.github.io/2021/10/05/python-crawler"></div><hr><ul class="pager"><li class="previous"><a href="/2021/10/08/python-fast-api/" data-toggle="tooltip" data-placement="top" title="Python FastAPI 快速入門">&larr; 上一篇</a></li><li class="next"><a href="/2021/10/04/progressive-web-application/pwa-publish-a-pwa-to-store/" data-toggle="tooltip" data-placement="top" title="Progressive Web App 跨平台安裝上架">下一篇 &rarr;</a></li></ul><br><div class="p-2 google-ad"><ins class="adsbygoogle" style="display:block" data-ad-format="autorelaxed" data-ad-client="ca-pub-1297466993744883" data-ad-slot="1800981579"></ins></div><div class="comment"><div id="disqus_thread" class="disqus-thread"></div></div></div><div class="col-lg-3 col-lg-offset-0 visible-lg-block sidebar-container catalog-container sticky__sidebar"><h5 id="-1" class="p-0"><a class="catalog-toggle" href="#">站內搜尋</a></h5><div id="site_search"><div class="form-group mt-3"><input type="text" id="local-search-input" inputmode="search" name="q" results="0" autocomplete="off" placeholder="請輸入關鍵字" class="st-search-input st-default-search-input form-control"></div><div id="local-search-result"></div></div><div class="side-catalog"><h5 id="-1"><a class="catalog-toggle" href="#">其他相關文章</a></h5><hr class="hidden-sm hidden-xs"><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-img"><img alt="yencheng" loading="lazy" src="https://fastapi.tiangolo.com/img/index/index-01-swagger-ui-simple.png"></div><div class="popular-posts-title"><h3><a href="/2021/10/08/python-fast-api/" title="Python FastAPI 快速入門" rel="bookmark">Python FastAPI 快速入門</a></h3><span>2021-10-08<span></span></span></div></li><li class="popular-posts-item"><div class="popular-posts-img"><img alt="yencheng" loading="lazy" src="/2019/08/01/python-hypothesis-testing/hypothesis-testing.png"></div><div class="popular-posts-title"><h3><a href="/2019/08/01/python-hypothesis-testing/" title="Python Hypothesis Testing (假設檢定)" rel="bookmark">Python Hypothesis Testing (假設檢定)</a></h3><span>2019-08-01<span></span></span></div></li><li class="popular-posts-item"><div class="popular-posts-img"><img alt="yencheng" loading="lazy" src="https://i0.wp.com/readlearncode.com/wp-content/uploads/2017/02/java-ee-7-apis.png?ssl=1"></div><div class="popular-posts-title"><h3><a href="/2018/04/05/java-web/" title="Java Web API (RESTful API) 教學" rel="bookmark">Java Web API (RESTful API) 教學</a></h3><span>2018-04-05<span></span></span></div></li></ul></div><div class="side-catalog mt-3"><h5 class="widget-title">最新的文章</h5><hr class="hidden-sm hidden-xs"><div class="widget"><ul class="p-0 popular-posts"><li class="popular-posts-item"><div class="popular-posts-img"><img loading="lazy" src="https://linyencheng.github.io/img/icon_48.png"></div><div class="popular-posts-title"><h3 id="progressive-web-app-1"><a href="/2025/08/10/kimetsu-no-yaiba/agatsuma-zenitsu-learn-one-thing/" title="我妻善逸教會我的事情" rel="bookmark">我妻善逸教會我的事情</a></h3><span>2025-08-11</span></div></li><li class="popular-posts-item"><div class="popular-posts-img"><img loading="lazy" src="https://linyencheng.github.io/img/icon_48.png"></div><div class="popular-posts-title"><h3 id="progressive-web-app-1"><a href="/2025/08/10/kimetsu-no-yaiba/kibutsuji-muzan-boss/" title="鬼舞辻無慘職場生存學" rel="bookmark">鬼舞辻無慘職場生存學</a></h3><span>2025-08-11</span></div></li><li class="popular-posts-item"><div class="popular-posts-img"><img loading="lazy" src="https://linyencheng.github.io/img/icon_48.png"></div><div class="popular-posts-title"><h3 id="progressive-web-app-1"><a href="/2025/08/09/kimetsu-no-yaiba/rengoku-kyoujurou-be-true-be-you/" title="炎柱的人生信念" rel="bookmark">炎柱的人生信念</a></h3><span>2025-08-11</span></div></li></ul></div></div><div class="side-catalog mt-3 google-ad"><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1297466993744883" data-ad-slot="9240487898" data-ad-format="auto" data-full-width-responsive="true"></ins></div></div><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 sidebar-container"></div></div></div></article><script>var disqus_shortname="linyencheng",disqus_identifier="https://linyencheng.github.io/2021/10/05/python-crawler/",disqus_url="https://linyencheng.github.io/2021/10/05/python-crawler/";function loadLikeCo(){var e;(e=document.createElement("script")).type="text/javascript",e.defer=!0,e.src="//static.like.co/sdk/v1/button.js",(document.head||document.body).appendChild(e)}function loadDisqus(){var e;(e=document.createElement("script")).type="text/javascript",e.defer=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}var runningOnBrowser="undefined"!=typeof window,isBot=runningOnBrowser&&!("onscroll"in window)||"undefined"!=typeof navigator&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout(function(){var n;!isBot&&supportsIntersectionObserver?(n=new IntersectionObserver(function(e){e[0].isIntersecting&&(loadLikeCo(),n.disconnect())},{threshold:[0]})).observe(document.getElementById("likeCo")):loadLikeCo()},1),setTimeout(function(){var n;!isBot&&supportsIntersectionObserver?(n=new IntersectionObserver(function(e){e[0].isIntersecting&&(loadDisqus(),n.disconnect())},{threshold:[0]})).observe(document.getElementById("disqus_thread")):loadDisqus()},1)</script><script>function getQueryString(e){return Object.keys(e).map(t=>t+"="+e[t]).join("&")}function updateDom(t){t.result.viewCountTotal&&768<window.innerWidth&&(localStorage.setItem("2021%2F10%2F05%2Fpython-crawler%2F",JSON.stringify(t)),document.getElementById("viewCountTotal").innerHTML='| 👀 <span class="pl-1">'+t.result.viewCountTotal+"</span>")}function getViewCount(){var t=getQueryString({url:"2021%2F10%2F05%2Fpython-crawler%2F",title:"Python%20Crawler%20%E7%88%AC%E8%9F%B2%E5%85%A5%E9%96%80%E7%AF%84%E4%BE%8B",action:"read_viewCount"});fetch("https://script.google.com/macros/s/AKfycbzaNdmEmtd1OTLicwwL628yQsVLKV3eSkxKqIsgUZ3zVQKn2nAnCnrOGgMgT-T8364N/exec?"+t).then(t=>t.json()).then(t=>updateDom(t)).catch(t=>console.error(t))}function initViewCount(){var t=localStorage.getItem("2021%2F10%2F05%2Fpython-crawler%2F");t&&updateDom(JSON.parse(t)),setTimeout(()=>{getViewCount()},800)}initViewCount()</script><style>@media all and (min-width:800px){.anchorjs-link{position:absolute;left:-.75em;font-size:1.1em;margin-top:-.1em}}@media all and (max-width:800px){.google-ad{max-height:140px}}</style><footer><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a target="_blank" rel="noopener" aria-label="YenCheng's Medium" href="https://linyencheng-tw.medium.com/"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i> <i class="fa fa-medium fa-stack-1x fa-inverse"></i></span></a></li><li><a title="Facebook" target="_blank" rel="noopener" aria-label="YenCheng's Facebook" href="https://www.facebook.com/linyencheng.3mins"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i> <i class="fa fa-facebook fa-stack-1x fa-inverse"></i></span></a></li><li><a title="Github" target="_blank" rel="noopener" aria-label="YenCheng's Github" href="https://github.com/LinYenCheng"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i> <i class="fa fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a title="Linkedin" target="_blank" rel="noopener" href="https://www.linkedin.com/in/LinYenCheng"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i> <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted"><a title="隱私權政策" href="/pravicy">隱私權政策</a> | Copyright &copy; 前端三分鐘 2025<br>Theme by <a title="原作者" target="_blank" rel="noopener" href="http://huangxuan.me">Hux</a> <span style="display:inline-block;margin:0 5px">& </span>Ported by <a title="第二作者" target="_blank" rel="noopener" href="https://github.com/Kaijun/hexo-theme-huxblog">Kaijun</a></p></div></div></div></footer><script defer>function loadScript(e,t){let n=document.createElement("script");n.src=e,n.defer=!0,n.onload=()=>t(null),n.onerror=e=>t(e),setTimeout(()=>{document.head.appendChild(n)},800)}function loadCSS(e,t){var n=document.createElement("link");n.rel="preload",n.href=e,n.as="style",document.head.appendChild(n);let l=document.createElement("link");l.rel="stylesheet",l.href=e,l.onload=()=>t(null),l.onerror=e=>t(e),setTimeout(()=>{document.head.appendChild(l)},800)}loadCSS("https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css",()=>{console.log("load font-awesome.min.css")}),loadScript("https://linyencheng.github.io/js/jquery.min.js",function(){var e=window,t=document,n="script",l="dataLayer";e[l]=e[l]||[],e[l].push({"gtm.start":(new Date).getTime(),event:"gtm.js"}),e=t.getElementsByTagName(n)[0],(l=t.createElement(n)).defer=!0,l.src="https://www.googletagmanager.com/gtm.js?id=GTM-W5LMXCR",e.parentNode.insertBefore(l,e),window.initViewCountAll&&window.initViewCountAll(),window.initViewCount&&window.initViewCount();{document.querySelectorAll("#toc .toc-item:has(> .toc-child)").forEach(n=>{var e=n.querySelector(".toc-link");let t=document.createElement("i");t.classList.add("fa","fa-caret-down");var l=document.createElement("i");l.classList.add("fa","fa-caret-right"),n.prepend(t,l),l.classList.add("hide"),n.querySelectorAll("i").forEach(t=>{t.addEventListener("click",function(){var e=n.querySelector(".toc-child");e.style.display="none"===e.style.display?"block":"none",t.classList.toggle("hide"),t.nextElementSibling.classList.toggle("hide")})}),e.addEventListener("dblclick",function(){n.querySelector(".toc-child").style.display="none",t.classList.toggle("hide")}),e.addEventListener("click",function(){var e=n.querySelector(".toc-child");e.style.display="none"===e.style.display?"block":"none",t.classList.toggle("hide")})});let t=document.querySelector("#toc .toc-title");t&&(t.classList.add("clickable"),t.addEventListener("click",function(){var e=t.nextElementSibling;"none"===e.style.display?(e.style.display="block",caretDown.classList.remove("hide"),caretRight.classList.add("hide")):(e.style.display="none",caretDown.classList.add("hide"),caretRight.classList.remove("hide"))}))}loadScript("https://linyencheng.github.io/js/bootstrap.min.js",function(){loadScript("https://linyencheng.github.io/js/hux-blog.min.js",function(){setTimeout(()=>{searchFunc("/search.xml","local-search-input","local-search-result")},3e3),document.getElementById("tag_cloud")&&loadScript("https://linyencheng.github.io/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})})})})</script></body></html>